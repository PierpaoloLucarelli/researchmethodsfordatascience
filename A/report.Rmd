---
title: "Report Template coursework assignment A - 2018"
subtitle: "CS4125 Seminar Research Methodology for Data Science"
author: "Student names (student numbers)"
date: "2/11/2019"
output:
   pdf_document:
      fig_caption: true
      number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


\tableofcontents


#Part 1 - Design and set-up of true experiment 

##The motivation for the planned research. 
(Max 250 words)

## The theory underlying the research.  
(Max 250 words) Preferable based on theories reported in literature


##Research questions 
The research question that will be examined in the experiment (or alternatively the hypothesis that will be tested in the experiment)


##The related conceptual model 
This model should include:
*Independent variable(s)
*Dependent variable
*Mediating variable (at least 1)
*Moderating variable (at least 1)


##Experimental Design 
Note that the study should have a true experimental design

## Experimental procedure 
Describe how the experiment will be executed step by step


## Measures
Describe the measure that will be used

## Participants
Describe which participants will recruit in the study and how they will be recruited

## Suggested statistical analyses
Describe the statistical test you suggest to care out on the collected data

#Part 2 - Generalized linear models

## Question 1 Twitter sentiment analysis (Between groups - single factor) 

### Conceptual model
Make a conceptual model for the following research question: Is there a difference in the sentiment of the tweets related to the different celebrities?

### Collecting tweets, and data preparation
Include the annotated R script (excluding your personal Keys and Access Tokens information), but put echo=FALSE, so code is not included in the output pdf file.


```{r, echo=FALSE, message=FALSE, warning=FALSE, include = FALSE}

#during writing you could add "eval = FALSE",  kntr will than not run this code chunk (take some time do)

#setwd("~/surfdrive/Teaching/own teaching/IN4125 - Seminar Research Methodology for Data Science/2019/coursework A") 
# apple , note use / instead of \, which used by windows


#install.packages("twitteR", dependencies = TRUE)
library(twitteR)
#install.packages("RCurl", dependencies = T)
library(RCurl)
#install.packages("bitops", dependencies = T)
library(bitops)
#install.packages("plyr", dependencies = T)
library(plyr)
#install.packages('stringr', dependencies = T)
library(stringr)
#install.packages("NLP", dependencies = T)
#library(NLP)
#install.packages("tm", dependencies = T)
#library(tm)
#install.packages("wordcloud", dependencies=T)
#install.packages("RColorBrewer", dependencies=TRUE)
#library(RColorBrewer)
#library(wordcloud)
#install.packages("reshape", dependencies=T)
#library(reshape)

################### functions

  
clearTweets <- function(tweets, excl) {
  
  tweets.text <- sapply(tweets, function(t)t$getText()) #get text out of tweets 

  
  tweets.text = gsub('[[:cntrl:]]', '', tweets.text)
  tweets.text = gsub('\\d+', '', tweets.text)
  tweets.text <- str_replace_all(tweets.text,"[^[:graph:]]", " ") #remove graphic
  
  
  corpus <- Corpus(VectorSource(tweets.text))
  
  corpus_clean <- tm_map(corpus, removePunctuation)
  corpus_clean <- tm_map(corpus_clean, content_transformer(tolower))
  corpus_clean <- tm_map(corpus_clean, removeWords, stopwords("english"))
  corpus_clean <- tm_map(corpus_clean, removeNumbers)
  corpus_clean <- tm_map(corpus_clean, stripWhitespace)
  corpus_clean <- tm_map(corpus_clean, removeWords, c(excl,"http","https","httpst"))
  

  return(corpus_clean)
} 


## capture all the output to a file.

################# Collect from Twitter

# for creating a twitter app (apps.twitter.com) see youtube https://youtu.be/lT4Kosc_ers
#consumer_key <-'your key'
#consumer_scret <- 'your secret'
#access_token <- 'your access token'
#access_scret <- 'your access scret'

source("your_twitter.R") #this file will set my personal variables for my twitter app, adjust the name of this file. use the provide template your_twitter.R

setup_twitter_oauth(consumer_key,consumer_scret, access_token,access_scret) #connect to  twitter app


##### This example uses the following 3 celebrities: Donald Trump, Hillary Clinton, and Bernie Sanders
##  You should replace this with your own celebrities, at least 3, but more preferred 
##  Note that it will take the computer some to collect the tweets

tweets_T <- searchTwitter("#trump", n=1000, lang="en", resultType="recent") #1000 recent tweets about Donald Trump, in English (I think that 1500 tweets is max)
tweets_C <- searchTwitter("#obama", n=1000, lang="en", resultType="recent") #1000 recent tweets about Hillary Clinton
tweets_B <- searchTwitter("#ladygaga", n=1000, lang="en", resultType="recent") #1000 recent tweets about Bernie Sanders



######################## WordCloud
### This not requires in the assignment, but still fun to do 

# based on https://youtu.be/JoArGkOpeU0

#corpus_T<-clearTweets(tweets_T, c("trump","amp","realdonaldtrump","trumptrain","donald","trumps","alwaystrump")) #remove also some campain slogans
#wordcloud(corpus_T, max.words=50)

#corpus_C<-clearTweets(tweets_C, c("hillary","amp","clinton","hillarys"))
#wordcloud(corpus_C,  max.words=50)

#corpus_B<-clearTweets(tweets_B, c("bernie", "amp", "sanders","bernies"))
#wordcloud(corpus_B,  max.words=50)
##############################

######################## Sentiment analysis

tweets_T.text <- laply(tweets_T, function(t)t$getText()) #get text out of tweets 
tweets_C.text <- laply(tweets_C, function(t)t$getText()) #get text out of tweets
tweets_B.text <- laply(tweets_B, function(t)t$getText()) #get text out of tweets



#taken from https://github.com/mjhea0/twitter-sentiment-analysis
pos <- scan('positive-words.txt', what = 'character', comment.char=';') #read the positive words
neg <- scan('negative-words.txt', what = 'character', comment.char=';') #read the negative words

source("sentiment3.R") #load algoritm
# see sentiment3.R form more information about sentiment analysis. It assigns a intereger score
# by substracitng the number of occurrence of negative words from that of positive words

analysis_T <- score.sentiment(tweets_T.text, pos, neg)
analysis_C <- score.sentiment(tweets_C.text, pos, neg)
analysis_B <- score.sentiment(tweets_B.text, pos, neg)


sem<-data.frame(analysis_T$score, analysis_C$score, analysis_B$score)


semFrame <-melt(sem, measured=c(analysis_T.score,analysis_C.score, analysis_B.score ))
names(semFrame) <- c("Candidate", "score")
semFrame$Candidate <-factor(semFrame$Candidate, labels=c("Trump", "Obama", "Lady Gaga")) # change the labels for your celibrities

#The data you need for the analyses can be found in semFrame

```


```{r}
# EX 2
# Make a conceptual model for the following research question: Is there a
# difference in the sentiment of the tweets related to the different
# celebrities?

# conceptual model
# independant vairables: Tweets
# dependant vriables: Score (sentiment)
# mediator variables: List of negative words, List of positive words.
```

### Homogeneity of variance analysis
Analyze the homogeneity of variance of sentiments of the tweets of the different celebrities

```{r}
#include your code and output in the document
leveneTest(semFrame$score, semFrame$Candidate, center=mean)
```

### Visual inspection
Graphically examine the variation in tweets' sentiments for each celebrity (e.g. histogram, density plot) 

```{r}
#include your code and output in the document
# We can see that the p-value of the test is smaller than 0.05, therefore we can assume that the 3 sentiment distirbutions do not have equal variances. 
# We can visially inspect the variances of the 3 distirbutions to get some insight on why this might be the case: 
hist(analysisA$score)
hist(analysisB$score)
hist(analysisC$score)
```


### Mean sentiments
Graphically examine the mean sentiments of tweets for each celebrity

```{r}
#include your code and output in the document
plot(semFrame$score ~ semFrame$Candidate)
```

### Linear model
Use a linear model to analyze whether the knowledge to which celebrity a tweet relates has a significant impact on explaining the sentiments of the tweets. 

```{r}
#include your code and output in the document
semFrame$candidateF <- factor(semFrame$Candidate)
model01 <- lm(score~1, data = semFrame)
model02 <- lm(score~candidateF, data = semFrame)
anova(model01, model02)
anova(model02)
```

### Post Hoc analysis
If a model that includes the celebrity is better in explaining the sentiments of tweets than a model without such predictor, conduct a post-hoc analysis with e.g. Bonferroni correction, to examine which of celebrity tweets differ from the other celebrity tweets

```{r}
#include your code and output in the document
```

### Report section for a scientific publication
Write a small section for a scientific publication, in which you report the results of the analyses, and explain the conclusions that can be drawn.

The variances of the celebrity's tweets sentiment scores are: CelebA: 1.79, CelebB: 1.36, CelebC: 1.03
The means of the celebrity's tweets sentiment scores are: CelebA: 0.61, CelebB: -0.309, CelebC: 0.43

We can see that CelebA has a larger variance in tweets sentiment score, therefore it means that the celebrity has more mixed  
opinions with respect to CelebB and CelebC. CelebB and CelebC have a variance closer to zero, meaning that the overall sentiment # for these celebrities are more of the neutral type.

In all 3 cases, the means of the tweets sentiment scores are around 0. This means that overall the general sentiment for these  # celebrities are neutral. Howver, the mean sentiment of CelebB is below zero, while the other 2 celebrities have a mean sentiment score above zero, This means that on average CelebB gets more negative tweets in comparison to CelebA and CelebC


## Question 2 - Website visits (between groups - Two factors)

### Conceptual model
Make a conceptual model underlying this research question

dependent variables: pages
independent variables: version, portal

### Visual inspection
Graphically examine the variation in page visits for different factors levels (e.g. histogram, density plot etc.) 


```{r}

visits <- read.csv('webvisit1.csv')
visits$versionF <- factor(visits$version)
visits$portalF <- factor(visits$portal)


#include your code and output in the document
visits0 <- visits[visits$version == 0,]
hist(visits0$pages)
visits0 <- visits[visits$version == 1,]
hist(visits0$pages)
visits0 <- visits[visits$portal == 0,]
hist(visits0$pages)
visits0 <- visits[visits$portal == 1,]
hist(visits0$pages)
```


### Normality check
Statistically test if variable page visits deviates from normal distribution


```{r}
#include your code and output in the document
shapiro.test(visits$pages)
```
p-value is very small, variable "pages" does not follow a normal distribution

### Model analysis
Conduct a model analysis, to examine the added values of adding 2 factors and interaction between the factors in the model to predict page visits.


```{r}
#include your code and output in the document
model0 <-lm(pages~1 , data = visits, na.action = na.exclude)
model1 <-lm(pages~version  , data = visits, na.action = na.exclude)
model2 <-lm(pages~portal , data = visits, na.action = na.exclude)
model3 <-lm(pages~version+portal , data = visits, na.action = na.exclude)
model4 <-lm(pages~version+portal+version*portal , data = visits, na.action = na.exclude)

anova(model0,model1)
anova(model0,model2)
anova(model3,model4)
anova(model4)
```


###Simple effect analysis
If the analysis shows a significant two-way interaction effect, conduct a Simple Effect analysis to explore this interaction effect in more detail.It helps first to look at the means in a figure


```{r}
#include your code and output in the document

```


### Report section for a scientific publication
Write a small section for a scientific publication, in which you report the results of the analyses, and explain the conclusions that can be drawn.

By viewing the results of the anova test, we can see that both adding portal and version information have an significant effect on the model. Secondly, we compare the model containing both the varables (version adn portal) with the model containing also the interaction between the two variables. This also shows that the inclusion of the intercacion of the two variables in the model has a significant effect on the model. Therefore the model which should be used to perorm a linear regression on this data should be model4. However, we can see by analyzing the histogram of the page visits, that the distribution of the data is very skewed to one side. This makes is harder to obtain a well-performing linear model for this data. In fact if we inspect the R-squared value of the anova test, we see only a result of 0.22% showing that this model does not accurately fit the data. 

##Question 3 - Linear regression analysis

### Conceptual model
Make a conceptual model underlying this research question

### Visual inspection
Graphical analysis of the distribution of the dependent variable, e.g. histogram, density plot 


```{r}
#include your code and output in the document
```


### Scatter plot
Scatter plots between dependent variable and the predictor variables


```{r}
#include your code and output in the document
```


### Linear regression
Conduct a multiple linear regression (including confidence intervals, and beta-values)


```{r}
#include your code and output in the document
```


### Examine assumption
Examine assumptions underlying linear regression. E.g collinearity and analyses of the residuals, e.g. normal distributed, linearity assumption, homogeneity of variance assumption. Where possible support examination with visual inspection.


```{r}
#include your code and output in the document
```


### Impact analysis of individual cases
Examine effect of single cases on the predicted values (e.g. DFBeta, Cook's distance)


```{r}
#include your code and output in the document
```


### Report section for a scientific publication
Write a small section for a scientific publication, in which you report the results of the analyses, and explain the conclusions that can be drawn.

## Question 4 - Logistic regression analysis

### Conceptual model
Make a conceptual model underlying this research question

### Logistic regression
Conduct a logistic regression, examine whether adding individual indicators in the model improves the model compared to Null model. Make a final model with only significant predictor(s). For this model, calculate the pseudo R-square. Calculate the odd ratio for the predictors and their confidence interval


```{r}
#include your code and output in the document
```

### Crosstable predicted and observed responses
Make a crosstable of the predicted and observed response


```{r}
#include your code and output in the document
```

### Report section for a scientific publication
Write a small section for a scientific publication, in which you report the results of the analyses, and explain the conclusions that can be drawn.

# Part 3 - Multilevel model

## Visual inspection
Use graphics to inspect the distribution of the score, and relationship between session and score


```{r}
#include your code and output in the document
```

## Multilevel analysis
Conduct multilevel analysis and calculate 95% confidence intervals, determine:

* If session has an impact on people score
* If there is significant variance between the participants in their score


```{r}
#include your code and output in the document
```

## Report section for a scientific publication
Write a small section for a scientific publication, in which you report the results of the analyses, and explain the conclusions that can be drawn.

